{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Filtering by specific postal code for spatial map plotting (Bukit Purmei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates for postal code 090112: Longitude 103.82593292805574, Latitude 1.2745285256209595\n",
      "Coordinates for postal code 090114: Longitude 103.82588719010951, Latitude 1.2750718182249274\n",
      "Coordinates for postal code 090113: Longitude 103.82693226761857, Latitude 1.2747701258018154\n",
      "Coordinates for postal code 090115: Longitude 103.82695018030107, Latitude 1.2753520132629723\n"
     ]
    }
   ],
   "source": [
    "# Exporting data for blocks of interest and control blocks\n",
    "import geopandas as gpd\n",
    "\n",
    "geojson_path = \"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\ADDRPT.geojson\"\n",
    "postal_code_112 = \"090112\"\n",
    "postal_code_114 = \"090114\"\n",
    "postal_code_113 = \"090113\"\n",
    "postal_code_115 = \"090115\"\n",
    "\n",
    "# Load the GeoJSON file\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Function to retrieve coordinates by postal code\n",
    "def get_coordinates_by_postal_code(postal_code):\n",
    "    # Filter GeoDataFrame for the given postal code\n",
    "    filtered_gdf = gdf[gdf['POSTAL_CODE'] == postal_code]\n",
    "    if not filtered_gdf.empty:\n",
    "        # Extract coordinates\n",
    "        point = filtered_gdf.iloc[0].geometry\n",
    "        return point.x, point.y\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "longitude_112, latitude_112 = get_coordinates_by_postal_code(postal_code_112)\n",
    "longitude_114, latitude_114 = get_coordinates_by_postal_code(postal_code_114)\n",
    "longitude_113, latitude_113 = get_coordinates_by_postal_code(postal_code_113)\n",
    "longitude_115, latitude_115 = get_coordinates_by_postal_code(postal_code_115)\n",
    "\n",
    "if longitude_112 and latitude_112 and longitude_114 and latitude_114:\n",
    "    print(f'Coordinates for postal code {postal_code_112}: Longitude {longitude_112}, Latitude {latitude_112}')\n",
    "    print(f'Coordinates for postal code {postal_code_114}: Longitude {longitude_114}, Latitude {latitude_114}')\n",
    "    print(f'Coordinates for postal code {postal_code_113}: Longitude {longitude_113}, Latitude {latitude_113}')\n",
    "    print(f'Coordinates for postal code {postal_code_115}: Longitude {longitude_115}, Latitude {latitude_115}')\n",
    "else:\n",
    "    print('Postal code not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central coordinates:\n",
      "Longitude: 103.82642564152123, Latitude: 1.2749306207276687\n"
     ]
    }
   ],
   "source": [
    "# Finding the central postal code for Blocks 112, 114, 113 and 115\n",
    "if longitude_112 and latitude_112 and longitude_114 and latitude_114:\n",
    "    # Calculate the average coordinates\n",
    "    avg_longitude = (longitude_112 + longitude_114 + longitude_113 + longitude_115) / 4\n",
    "    avg_latitude = (latitude_112 + latitude_114 + latitude_113 + latitude_115) / 4\n",
    "    print(f'Central coordinates:')\n",
    "    print(f'Longitude: {avg_longitude}, Latitude: {avg_latitude}')\n",
    "else:\n",
    "    print('Postal code not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting x and y to coordinates for latitude/longitude\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import Point\n",
    "\n",
    "global filtered_df\n",
    "\n",
    "def preprocessing(file_path):   \n",
    "    global filtered_df\n",
    "    \n",
    "    # Open your GeoTIFF file\n",
    "    with rasterio.open(file_path) as src:\n",
    "        array = src.read()\n",
    "        transform = src.transform\n",
    "        src_crs = src.crs  # Source CRS\n",
    "        dest_crs = 'EPSG:4326'  # WGS 84\n",
    "\n",
    "        # Create a transformer object to convert from src_crs to dest_crs\n",
    "        transformer = Transformer.from_crs(src_crs, dest_crs, always_xy=True)\n",
    "\n",
    "        # Get arrays of column and row indices\n",
    "        cols, rows = np.meshgrid(np.arange(array.shape[2]), np.arange(array.shape[1]))\n",
    "        \n",
    "        # Convert meshgrid arrays to coordinate arrays using rasterio's method, which are 2D\n",
    "        xs, ys = rasterio.transform.xy(transform, rows, cols, offset='center')\n",
    "        \n",
    "        # Flatten the coordinate arrays to pass to transform function\n",
    "        lon, lat = transformer.transform(np.array(xs).flatten(), np.array(ys).flatten())\n",
    "\n",
    "        # Create DataFrame and convert to GeoDataFrame\n",
    "        df = pd.DataFrame({'Longitude': lon, 'Latitude': lat})\n",
    "        for i, band in enumerate(src.read(masked=True)):\n",
    "            df[src.descriptions[i]] = band.flatten()\n",
    "\n",
    "        # Convert 'SR_QA_AEROSOL' to integer for bitwise operation\n",
    "        df['SR_QA_AEROSOL'] = df['SR_QA_AEROSOL'].astype(int)\n",
    "\n",
    "        # Filter out pixels with valid aerosol retrieval and high aerosol level\n",
    "        # Assuming 'SR_QA_AEROSOL' is the name of the QA aerosol band in the data\n",
    "        valid_aerosol = (df['SR_QA_AEROSOL'] & 2) == 2  # Bit 1 must be set for valid retrieval\n",
    "        high_aerosol = (df['SR_QA_AEROSOL'] & 192) == 192  # Bits 6-7 must be set to 11 for high aerosol\n",
    "        filter_mask = valid_aerosol & high_aerosol\n",
    "        df_filtered = df[-filter_mask]\n",
    "        \n",
    "        # Scale and offset specific bands\n",
    "        df_filtered['ST_B10_Celsius'] = df_filtered['ST_B10'] * 0.00341802 + 149 - 273.15\n",
    "        df_filtered = df_filtered[df_filtered['ST_B10_Celsius'] >= 20]  # Drop rows below 20 degrees Celsius\n",
    "        \n",
    "        bands_to_scale = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "        for band in bands_to_scale:\n",
    "            df_filtered[f\"{band}_Scaled\"] = df_filtered[band] * 2.75e-05 - 0.2\n",
    "\n",
    "        additional_scales = {\n",
    "            'ST_ATRAN': 0.0001, 'ST_CDIST': 0.01, 'ST_DRAD': 0.001, \n",
    "            'ST_EMIS': 0.0001, 'ST_EMSD': 0.0001, 'ST_QA': 0.01, \n",
    "            'ST_TRAD': 0.001, 'ST_URAD': 0.001\n",
    "        }\n",
    "\n",
    "        for band, scale in additional_scales.items():\n",
    "            df_filtered[f\"{band}_Scaled\"] = df_filtered[band] * scale\n",
    "\n",
    "        gdf = gpd.GeoDataFrame(df_filtered, geometry=gpd.points_from_xy(df_filtered.Longitude, df_filtered.Latitude))\n",
    "        gdf.set_crs('EPSG:4326', inplace=True)  # Ensure the CRS is set to WGS 84\n",
    "\n",
    "        print(\"Total number of valid pixels: \" + str(len(gdf)))\n",
    "        print(df[['Latitude', 'Longitude']].head())\n",
    "\n",
    "        # Define your point of interest and buffer distance in meters\n",
    "        poi = Point(avg_longitude, avg_latitude)\n",
    "        desired_radius = 200\n",
    "        buffer = poi.buffer(desired_radius / 111320)  # Convert meters to degrees approximately\n",
    "\n",
    "        # Filter points within the buffer\n",
    "        filtered_gdf = gdf[gdf.geometry.within(buffer)]\n",
    "\n",
    "        # Save or process your filtered data\n",
    "        print(f\"\\nNumber of points within {desired_radius}m radius: {len(filtered_gdf)}\")\n",
    "        #print(filtered_gdf['ST_B10_Celsius'].head())\n",
    "\n",
    "    return filtered_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining boundaries and plotting region of interest using GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['osm_id', 'osm_type', 'addr_street', 'building', 'name', 'access_roof',\n",
      "       'building_material', 'addr_housenumber', 'roof_material', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "geojson_path = \"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\SG_geojson\\\\SG.geojson\"\n",
    "\n",
    "geo_data = gpd.read_file(geojson_path)\n",
    "\n",
    "# Display the matching features\n",
    "print(geo_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLYGON ((103.8254384 1.2743995, 103.825484 1.2743955, 103.8254826 1.2743647, 103.8257254 1.274362, 103.8257254 1.2744009, 103.8260325 1.2743915, 103.8260754 1.2744344, 103.8262618 1.274429, 103.8263745 1.2745524, 103.8263785 1.2747656, 103.8262082 1.2747669, 103.8262045 1.274549, 103.8257106 1.2745598, 103.8257079 1.2745108, 103.8254424 1.2745122, 103.8254384 1.2743995))\n",
      "POLYGON ((103.8254451 1.274657, 103.8255926 1.2746516, 103.8255886 1.2750116, 103.8256382 1.2750605, 103.8258664 1.2750513, 103.8258635 1.2749908, 103.8261706 1.2749835, 103.8261733 1.2750663, 103.82622 1.2750652, 103.8262177 1.2749582, 103.826303 1.2749563, 103.8263065 1.2751152, 103.8263989 1.2751132, 103.8264009 1.2752002, 103.8262434 1.2752037, 103.8262454 1.2752961, 103.8261471 1.2752983, 103.8261437 1.2751449, 103.8258625 1.2751533, 103.8258635 1.2751839, 103.8255618 1.2751933, 103.8254545 1.2750927, 103.8254451 1.274657))\n",
      "POLYGON ((103.8264643 1.2746563, 103.8268371 1.2746362, 103.8268412 1.2746898, 103.8270133 1.2746847, 103.827013 1.2747262, 103.8272475 1.274718, 103.8273682 1.2748239, 103.8273759 1.2750803, 103.8272046 1.275086, 103.8271993 1.2748183, 103.8268457 1.27483, 103.8268442 1.2748025, 103.8264737 1.2748159, 103.8264643 1.2746563))\n",
      "POLYGON ((103.8264791 1.2749426, 103.8266159 1.2749426, 103.8266239 1.2752985, 103.8266789 1.2753441, 103.826868 1.2753354, 103.8268653 1.2752871, 103.8270262 1.2752804, 103.8270262 1.2752308, 103.8272086 1.2752228, 103.8272096 1.2752788, 103.8272529 1.2752764, 103.8272489 1.2751624, 103.827336 1.2751598, 103.8273389 1.2753173, 103.8274248 1.2753141, 103.8274277 1.2754222, 103.8272797 1.2754266, 103.8272797 1.2755305, 103.8271832 1.2755338, 103.8271764 1.2753569, 103.8270665 1.2753622, 103.8270665 1.2754165, 103.8268895 1.2754239, 103.8268908 1.2754775, 103.8266011 1.2754815, 103.8264911 1.2753797, 103.8264791 1.2749426))\n"
     ]
    }
   ],
   "source": [
    "blocks_of_interest = ['112', '114', '113', '115']\n",
    "\n",
    "polygons = {}\n",
    "\n",
    "for block in blocks_of_interest:\n",
    "    matching_features = geo_data[(geo_data['addr_street'].str.contains(\"Bukit Purmei\", na=False)) & \n",
    "                                (geo_data['addr_housenumber'].str.contains(f\"{block}\", na=False))]\n",
    "\n",
    "    if not matching_features.empty:\n",
    "        polygon = matching_features.iloc[0]['geometry']\n",
    "        polygons[f'polygon_{block}'] = polygon\n",
    "        print(polygons[f'polygon_{block}'])\n",
    "    else:\n",
    "        print(\"No matching features found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering 30m x 30m pixels based on region of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using ESPG:3857 allows you to blow up the pixels in metres because the coordinate representation is in metres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.2/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"b210dcaf-0205-416d-8c89-6a7ef99bb748\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"10977656-1c6f-41fb-a99e-b9d2960c8c4d\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"3d9f2d7bd3af4e639eba0208fa2bdbae\",\"client_comm_id\":\"6051289c9cb64e609367fe27a5fa14c4\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"10977656-1c6f-41fb-a99e-b9d2960c8c4d\",\"roots\":{\"p1002\":\"b210dcaf-0205-416d-8c89-6a7ef99bb748\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, box\n",
    "import panel as pn\n",
    "from bokeh.palettes import Inferno256\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Suppress warnings\n",
    "logging.getLogger('bokeh').setLevel(logging.ERROR)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "global within_polygon_gdf\n",
    "\n",
    "def plot_spatial_map(filtered_gdf): \n",
    "    global within_polygon_gdf\n",
    "    \n",
    "    filtered_gdf = filtered_gdf.to_crs('epsg:3857')\n",
    "\n",
    "    # print(filtered_gdf['geometry'])\n",
    "\n",
    "    # Create pixels as 30m x 30m boxes around each point\n",
    "    # Assuming each point is at the center of the pixel\n",
    "    half_width = 15  # half the width of the pixel in meters since the ESPG:3857 coordinate system is in metres\n",
    "    filtered_gdf['geometry'] = filtered_gdf['geometry'].apply(lambda x: box(x.x - half_width, x.y - half_width, x.x + half_width, x.y + half_width))\n",
    "\n",
    "    #print(filtered_gdf['geometry'])\n",
    "\n",
    "    # Create a GeoDataFrame from all polygons and convert CRS to match\n",
    "    polygon_gdf = gpd.GeoDataFrame({'geometry': list(polygons.values())}, crs='epsg:4326')\n",
    "    polygon_gdf_3857 = polygon_gdf.to_crs('epsg:3857')\n",
    "\n",
    "    # Filter points that intersect any polygon\n",
    "    def intersects_any_polygon(point):\n",
    "        return any(point.intersects(poly) for poly in polygon_gdf['geometry'])\n",
    "    \n",
    "    filtered_gdf['intersects'] = filtered_gdf['geometry'].apply(intersects_any_polygon)\n",
    "\n",
    "    # Check intersection with any polygon\n",
    "    within_polygon_gdf = filtered_gdf[filtered_gdf['intersects']].copy()\n",
    "\n",
    "    # print(polygon_gdf_3857['geometry'])\n",
    "\n",
    "    # Filter points that intersect any polygon\n",
    "    filtered_gdf['intersects'] = filtered_gdf['geometry'].apply(\n",
    "        lambda geom: any(geom.intersects(poly) for poly in polygon_gdf_3857['geometry']))\n",
    "    within_polygon_gdf = filtered_gdf[filtered_gdf['intersects']].copy()\n",
    "\n",
    "    print(\"Number of pixels in region of interest: \" + str(len(within_polygon_gdf)))\n",
    "\n",
    "    # Print or use the filtered GeoDataFrame as needed\n",
    "    # print(\"\\nNumber of points within the region of interest: \" + str(len(within_polygon_gdf)))\n",
    "\n",
    "    # # Print the centroids of the intersected pixels\n",
    "    # for index, row in within_polygon_gdf.iterrows():\n",
    "    #     centroid = row['geometry'].centroid\n",
    "    #     print(f\"Longitude: {centroid.x}, Latitude: {centroid.y}\")\n",
    "\n",
    "    # Define a function to select a subset of the color palette\n",
    "    def select_colors(palette, n):\n",
    "        return [palette[int(i)] for i in np.linspace(0, len(palette)-1, n)]\n",
    "\n",
    "    # Create a custom color scale using a continuous palette\n",
    "    custom_palette = select_colors(Inferno256, 256)  # More colors for smoother transitions\n",
    "\n",
    "    # Create the heatmap using the centroid points of intersected pixels\n",
    "    heatmap = within_polygon_gdf.hvplot.points('Longitude', 'Latitude', geo=True, c='ST_B10_Celsius', cmap=custom_palette, size=5, tiles='OSM', frame_width=700, frame_height=500, colorbar=True, clim=(20, 40))\n",
    "\n",
    "    # Plot square polygons with the same color mapping as the points\n",
    "    squares_plot = within_polygon_gdf.hvplot.polygons('geometry', c='ST_B10_Celsius', cmap=custom_palette, alpha=0.5, colorbar=True, clim=(20, 40))\n",
    "\n",
    "    # Plot the polygon with visible settings\n",
    "    polygon_plot = polygon_gdf.hvplot(geo=True, color='red', line_width=3, alpha=0.7)\n",
    "\n",
    "    # Overlay the polygon onto the heatmap\n",
    "    overlay_map = polygon_plot * heatmap * squares_plot\n",
    "\n",
    "    # Set up Panel to display the plot\n",
    "    # pane = pn.panel(overlay_map)\n",
    "\n",
    "    # pane.show()\n",
    "    # pane.save(f'C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\MSE-ES-UHI\\\\2_landsat\\\\Heatmaps\\\\{postal_code_112}_{satellite_image}_LST_Filtered.html', embed=True)\n",
    "\n",
    "    return overlay_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting LST over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combining GDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing: L8_UTC_20200106_031650.tif\n",
      "Total number of valid pixels: 1912476\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 134\n",
      "Currently processing: L8_UTC_20200122_031646.tif\n",
      "Total number of valid pixels: 1731121\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 135\n",
      "Currently processing: L8_UTC_20200207_031641.tif\n",
      "Total number of valid pixels: 1216672\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 0\n",
      "Currently processing: L8_UTC_20200223_031638.tif\n",
      "Total number of valid pixels: 1345446\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 129\n",
      "Currently processing: L8_UTC_20200310_031632.tif\n",
      "Total number of valid pixels: 1314431\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 119\n",
      "Currently processing: L8_UTC_20200326_031623.tif\n",
      "Total number of valid pixels: 1395941\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 11\n",
      "Currently processing: L8_UTC_20200411_031615.tif\n",
      "Total number of valid pixels: 924801\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 113\n",
      "Currently processing: L8_UTC_20200427_031608.tif\n",
      "Total number of valid pixels: 0\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 0\n",
      "Currently processing: L8_UTC_20200529_031605.tif\n",
      "Total number of valid pixels: 1377754\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 124\n",
      "Currently processing: L8_UTC_20200614_031616.tif\n",
      "Total number of valid pixels: 37446\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 0\n",
      "Currently processing: L8_UTC_20200630_031624.tif\n",
      "Total number of valid pixels: 1104217\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 124\n",
      "Currently processing: L8_UTC_20200716_031630.tif\n",
      "Total number of valid pixels: 2045133\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 131\n",
      "Currently processing: L8_UTC_20200801_031634.tif\n",
      "Total number of valid pixels: 28641\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 0\n",
      "Currently processing: L8_UTC_20200817_031639.tif\n",
      "Total number of valid pixels: 558821\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 0\n",
      "Currently processing: L8_UTC_20200902_031647.tif\n",
      "Total number of valid pixels: 1445605\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 131\n",
      "Currently processing: L8_UTC_20200918_031653.tif\n",
      "Total number of valid pixels: 1183017\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 124\n",
      "Currently processing: L8_UTC_20201004_031657.tif\n",
      "Total number of valid pixels: 0\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 0\n",
      "Currently processing: L8_UTC_20201020_031658.tif\n",
      "Total number of valid pixels: 0\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 0\n",
      "Currently processing: L8_UTC_20201121_031657.tif\n",
      "Total number of valid pixels: 317897\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 47\n",
      "Currently processing: L8_UTC_20201207_031659.tif\n",
      "Total number of valid pixels: 955530\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 119\n",
      "Currently processing: L8_UTC_20201223_031657.tif\n",
      "Total number of valid pixels: 476280\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 200m radius: 127\n",
      "          Longitude  Latitude   SR_B1    SR_B2    SR_B3    SR_B4    SR_B5  \\\n",
      "1273224  103.826034  1.276485  9837.0  10206.0  11618.0  12757.0  17341.0   \n",
      "1273225  103.826304  1.276485  8668.0   8884.0  10165.0  10321.0  20619.0   \n",
      "1273226  103.826573  1.276485  8534.0   8537.0   9528.0   8659.0  21533.0   \n",
      "1273227  103.826843  1.276485  8808.0   9070.0  10060.0   9498.0  21045.0   \n",
      "1273228  103.827113  1.276486  8730.0   9173.0  10355.0  10037.0  19299.0   \n",
      "...             ...       ...     ...      ...      ...      ...      ...   \n",
      "1292830  103.827114  1.273501  8239.0   8732.0  10343.0   9871.0  17899.0   \n",
      "1292831  103.827384  1.273501  8152.0   8870.0  10631.0  10288.0  17198.0   \n",
      "1294608  103.826036  1.273229  9226.0   9986.0  11428.0  11595.0  16193.0   \n",
      "1294609  103.826305  1.273229  7916.0   8338.0   9856.0   9206.0  16562.0   \n",
      "1294610  103.826575  1.273229  7911.0   8233.0   9549.0   8809.0  16353.0   \n",
      "\n",
      "           SR_B6    SR_B7  SR_QA_AEROSOL  ...  ST_ATRAN_Scaled  \\\n",
      "1273224  17943.0  16129.0            224  ...           0.4133   \n",
      "1273225  17035.0  13259.0            160  ...           0.4133   \n",
      "1273226  14406.0  10534.0             66  ...           0.4133   \n",
      "1273227  14042.0  10606.0            160  ...           0.4133   \n",
      "1273228  14536.0  11182.0            224  ...           0.4133   \n",
      "...          ...      ...            ...  ...              ...   \n",
      "1292830  15228.0  12174.0            224  ...           0.3477   \n",
      "1292831  16078.0  12956.0            224  ...           0.3477   \n",
      "1294608  14482.0  12457.0            192  ...           0.3477   \n",
      "1294609  13121.0  10774.0            224  ...           0.3477   \n",
      "1294610  12849.0  10642.0            224  ...           0.3477   \n",
      "\n",
      "         ST_CDIST_Scaled  ST_DRAD_Scaled  ST_EMIS_Scaled  ST_EMSD_Scaled  \\\n",
      "1273224             0.36           2.011          0.9761          0.0092   \n",
      "1273225             0.38           2.011          0.9821          0.0092   \n",
      "1273226             0.40           2.011          0.9856          0.0092   \n",
      "1273227             0.42           2.011          0.9837          0.0092   \n",
      "1273228             0.45           2.011          0.9840          0.0103   \n",
      "...                  ...             ...             ...             ...   \n",
      "1292830             0.00           2.164          0.9523          0.0128   \n",
      "1292831             0.00           2.164          0.9523          0.0128   \n",
      "1294608             0.00           2.164          0.9655          0.0128   \n",
      "1294609             0.00           2.164          0.9655          0.0128   \n",
      "1294610             0.00           2.164          0.9655          0.0128   \n",
      "\n",
      "         ST_QA_Scaled  ST_TRAD_Scaled  ST_URAD_Scaled  \\\n",
      "1273224          5.16        9.510000           4.729   \n",
      "1273225          5.06        9.501000           4.729   \n",
      "1273226          4.97        9.477000           4.729   \n",
      "1273227          4.87        9.437000           4.729   \n",
      "1273228          4.78        9.397000           4.729   \n",
      "...               ...             ...             ...   \n",
      "1292830          7.08        8.490001           5.133   \n",
      "1292831          7.07        8.496000           5.133   \n",
      "1294608          7.10        8.470000           5.133   \n",
      "1294609          7.11        8.462001           5.133   \n",
      "1294610          7.10        8.466001           5.133   \n",
      "\n",
      "                          geometry       time  \n",
      "1273224  POINT (103.82603 1.27649) 2020-01-06  \n",
      "1273225  POINT (103.82630 1.27649) 2020-01-06  \n",
      "1273226  POINT (103.82657 1.27649) 2020-01-06  \n",
      "1273227  POINT (103.82684 1.27649) 2020-01-06  \n",
      "1273228  POINT (103.82711 1.27649) 2020-01-06  \n",
      "...                            ...        ...  \n",
      "1292830  POINT (103.82711 1.27350) 2020-12-23  \n",
      "1292831  POINT (103.82738 1.27350) 2020-12-23  \n",
      "1294608  POINT (103.82604 1.27323) 2020-12-23  \n",
      "1294609  POINT (103.82631 1.27323) 2020-12-23  \n",
      "1294610  POINT (103.82657 1.27323) 2020-12-23  \n",
      "\n",
      "[1568 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import shutil\n",
    "\n",
    "year = \"2020\"\n",
    "\n",
    "# Suppress warnings\n",
    "logging.getLogger('bokeh').setLevel(logging.ERROR)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Specify the zip file and temporary directory for extraction\n",
    "zip_file_path = f\"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\Landsat8\\\\{year}.zip\"\n",
    "temp_dir = f\"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\temp_extract\"\n",
    "\n",
    "# Create a temporary directory if it doesn't exist\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# Extract the .tif files from the zip\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(temp_dir)\n",
    "\n",
    "# Initialize an empty list to hold all the GeoDataFrames\n",
    "gdfs = []\n",
    "\n",
    "# Walk through the temporary directory and process each .tif file\n",
    "for filename in os.listdir(f\"{temp_dir}\\\\{year}\"):\n",
    "    if filename.endswith(\".tif\"):\n",
    "        print(\"Currently processing: \" + filename)\n",
    "        file_path = os.path.join(f\"{temp_dir}\\\\{year}\", filename)\n",
    "        \n",
    "        # Extract the time period from the filename\n",
    "        # Assuming filename format is \"L8_UTC_YYYYMMDD_hhmmss.tif\"\n",
    "        time_str = filename.split('_')[2]\n",
    "        time_obj = datetime.strptime(time_str, \"%Y%m%d\")\n",
    "        \n",
    "        # Load and preprocess the GeoDataFrame\n",
    "        gdf = preprocessing(file_path)\n",
    "        gdf['time'] = time_obj  # Append the datetime object as a new column\n",
    "        \n",
    "        # Append the processed GeoDataFrame to the list\n",
    "        gdfs.append(gdf)\n",
    "\n",
    "# Combine all GeoDataFrames into one\n",
    "combined_gdf = pd.concat(gdfs)\n",
    "\n",
    "shutil.rmtree(f\"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\temp_extract\")\n",
    "\n",
    "# Use the combined GeoDataFrame as needed\n",
    "print(combined_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spatial plot over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying plot for 2020-01-06\n",
      "Number of pixels in region of interest: 32\n",
      "Launching server at http://localhost:60562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<panel.io.server.Server at 0x14b3418fbe0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import panel as pn\n",
    "\n",
    "# Create an interactive plot with filtering based on the GeoDataFrame\n",
    "def create_interactive_plot(combined_gdf):\n",
    "    # Create a list of unique dates sorted\n",
    "    unique_dates = combined_gdf['time'].dt.strftime('%Y-%m-%d').sort_values().unique()\n",
    "    # print(f\"Unique Dates: {unique_dates}\")\n",
    "\n",
    "    date_index_map = {i + 1: date for i, date in enumerate(unique_dates)}\n",
    "\n",
    "    # Setup an integer slider to select time periods\n",
    "    time_slider = pn.widgets.IntSlider(name='Select Time', start=1, end=len(unique_dates), value=1, step=1)\n",
    "\n",
    "    @pn.depends(time_slider.param.value_throttled)\n",
    "    def dynamic_map(value):\n",
    "        selected_date = date_index_map[value]\n",
    "        selected_datetime = pd.to_datetime(selected_date).date()\n",
    "        \n",
    "        # Filter data for the selected time\n",
    "        filtered_data = combined_gdf[combined_gdf['time'].dt.date == selected_datetime]\n",
    "        print(f\"Displaying plot for \" + str(selected_date))\n",
    "        \n",
    "        # Call plot_spatial_map for the selected time period\n",
    "        return plot_spatial_map(filtered_data)\n",
    "\n",
    "    layout = pn.Column(\n",
    "        \"<br>\\nInteractive Land Surface Temperature Map\",\n",
    "        time_slider,\n",
    "        dynamic_map\n",
    "    )\n",
    "\n",
    "    return layout\n",
    "\n",
    "layout = create_interactive_plot(combined_gdf)\n",
    "# layout.servable()\n",
    "pn.serve(layout, show=False, start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting data to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully exported to C:\\LocalOneDrive\\Documents\\Desktop\\MTI\\UHI-Project\\MSE-ES-UHI\\Data\\FilteredData\\BukitPurmei\\BukitPurmei_Filtered_2022.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying plot for 2020-02-23\n",
      "Number of pixels in region of interest: 31\n",
      "Displaying plot for 2020-04-11\n",
      "Number of pixels in region of interest: 31\n",
      "Displaying plot for 2020-01-06\n",
      "Number of pixels in region of interest: 32\n",
      "Displaying plot for 2020-01-22\n",
      "Number of pixels in region of interest: 33\n",
      "Displaying plot for 2020-03-10\n",
      "Number of pixels in region of interest: 32\n",
      "Displaying plot for 2020-04-11\n",
      "Number of pixels in region of interest: 31\n",
      "Displaying plot for 2020-06-30\n",
      "Number of pixels in region of interest: 31\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "\n",
    "def filter_and_save_data(year_gdf, polygons, output_file):\n",
    "    # Ensure polygons are in EPSG:3857\n",
    "    polygon_gdf = gpd.GeoDataFrame({'geometry': list(polygons.values())}, crs='epsg:4326')\n",
    "    polygon_gdf = polygon_gdf.to_crs('epsg:3857')\n",
    "\n",
    "    # Initialize an empty DataFrame to store all filtered data\n",
    "    all_filtered_data = gpd.GeoDataFrame()\n",
    "\n",
    "    for date in year_gdf['time'].dt.strftime('%Y-%m-%d').sort_values().unique():\n",
    "        # Filter data for the specific date\n",
    "        date_data = year_gdf[year_gdf['time'].dt.strftime('%Y-%m-%d') == date]\n",
    "\n",
    "        # Convert CRS to EPSG:3857 and create 30m x 30m boxes around each point\n",
    "        date_data = date_data.to_crs('epsg:3857')\n",
    "        date_data['geometry'] = date_data['geometry'].apply(\n",
    "            lambda x: box(x.x - 15, x.y - 15, x.x + 15, x.y + 15))\n",
    "\n",
    "        # Filter points that intersect any polygon\n",
    "        date_data['intersects'] = date_data['geometry'].apply(\n",
    "            lambda geom: any(geom.intersects(poly) for poly in polygon_gdf['geometry']))\n",
    "        filtered_data = date_data[date_data['intersects']].copy()\n",
    "\n",
    "        # Append the filtered data of this date to the all_filtered_data DataFrame\n",
    "        all_filtered_data = pd.concat([all_filtered_data, filtered_data], ignore_index=True)\n",
    "\n",
    "    # Drop the 'geometry' column as it cannot be saved directly in CSV format\n",
    "    all_filtered_data.drop(columns=['geometry'], inplace=True)\n",
    "\n",
    "    # Save the aggregated filtered data to a CSV file\n",
    "    all_filtered_data.to_csv(output_file, index=False)\n",
    "    print(f\"Data successfully exported to {output_file}\")\n",
    "\n",
    "combined_gdf['time'] = pd.to_datetime(combined_gdf['time'])  # Ensure 'time' is a datetime object\n",
    "output_path = 'C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\FilteredData\\\\BukitPurmei\\\\BukitPurmei_Filtered_2022.csv'\n",
    "filter_and_save_data(combined_gdf, polygons, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
