{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Filtering by specific postal code for spatial map plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates for postal code 090112: Longitude 103.82593292805574, Latitude 1.2745285256209595\n",
      "Coordinates for postal code 090114: Longitude 103.82588719010951, Latitude 1.2750718182249274\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "geojson_path = \"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\ADDRPT.geojson\"\n",
    "postal_code_112 = \"090112\"\n",
    "postal_code_114 = \"090114\"\n",
    "\n",
    "# Load the GeoJSON file\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Function to retrieve coordinates by postal code\n",
    "def get_coordinates_by_postal_code(postal_code):\n",
    "    # Filter GeoDataFrame for the given postal code\n",
    "    filtered_gdf = gdf[gdf['POSTAL_CODE'] == postal_code]\n",
    "    if not filtered_gdf.empty:\n",
    "        # Extract coordinates\n",
    "        point = filtered_gdf.iloc[0].geometry\n",
    "        return point.x, point.y\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "longitude_112, latitude_112 = get_coordinates_by_postal_code(postal_code_112)\n",
    "longitude_114, latitude_114 = get_coordinates_by_postal_code(postal_code_114)\n",
    "\n",
    "if longitude_112 and latitude_112 and longitude_114 and latitude_114:\n",
    "    print(f'Coordinates for postal code {postal_code_112}: Longitude {longitude_112}, Latitude {latitude_112}')\n",
    "    print(f'Coordinates for postal code {postal_code_114}: Longitude {longitude_114}, Latitude {latitude_114}')\n",
    "else:\n",
    "    print('Postal code not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average coordinates between postal codes 090112 and 090114:\n",
      "Longitude: 103.82591005908262, Latitude: 1.2748001719229434\n"
     ]
    }
   ],
   "source": [
    "# Finding the central postal code for Blocks 112 and 114\n",
    "if longitude_112 and latitude_112 and longitude_114 and latitude_114:\n",
    "    # Calculate the average coordinates\n",
    "    avg_longitude = (longitude_112 + longitude_114) / 2\n",
    "    avg_latitude = (latitude_112 + latitude_114) / 2\n",
    "    print(f'Average coordinates between postal codes {postal_code_112} and {postal_code_114}:')\n",
    "    print(f'Longitude: {avg_longitude}, Latitude: {avg_latitude}')\n",
    "else:\n",
    "    print('Postal code not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting x and y to coordinates for latitude/longitude\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def preprocessing(file_path):   \n",
    "    # Open your GeoTIFF file\n",
    "    with rasterio.open(file_path) as src:\n",
    "        array = src.read()\n",
    "        transform = src.transform\n",
    "        src_crs = src.crs  # Source CRS\n",
    "        dest_crs = 'EPSG:4326'  # WGS 84\n",
    "\n",
    "        # Create a transformer object to convert from src_crs to dest_crs\n",
    "        transformer = Transformer.from_crs(src_crs, dest_crs, always_xy=True)\n",
    "\n",
    "        # Get arrays of column and row indices\n",
    "        cols, rows = np.meshgrid(np.arange(array.shape[2]), np.arange(array.shape[1]))\n",
    "        \n",
    "        # Convert meshgrid arrays to coordinate arrays using rasterio's method, which are 2D\n",
    "        xs, ys = rasterio.transform.xy(transform, rows, cols, offset='center')\n",
    "        \n",
    "        # Flatten the coordinate arrays to pass to transform function\n",
    "        lon, lat = transformer.transform(np.array(xs).flatten(), np.array(ys).flatten())\n",
    "\n",
    "        # Create DataFrame and convert to GeoDataFrame\n",
    "        df = pd.DataFrame({'Longitude': lon, 'Latitude': lat})\n",
    "        for i, band in enumerate(src.read(masked=True)):\n",
    "            df[src.descriptions[i]] = band.flatten()\n",
    "\n",
    "        # Convert 'SR_QA_AEROSOL' to integer for bitwise operation\n",
    "        df['SR_QA_AEROSOL'] = df['SR_QA_AEROSOL'].astype(int)\n",
    "\n",
    "        # Filter out pixels with valid aerosol retrieval and high aerosol level\n",
    "        # Assuming 'SR_QA_AEROSOL' is the name of the QA aerosol band in the data\n",
    "        valid_aerosol = (df['SR_QA_AEROSOL'] & 2) == 2  # Bit 1 must be set for valid retrieval\n",
    "        high_aerosol = (df['SR_QA_AEROSOL'] & 192) == 192  # Bits 6-7 must be set to 11 for high aerosol\n",
    "        filter_mask = valid_aerosol & high_aerosol\n",
    "        df_filtered = df[-filter_mask]\n",
    "        \n",
    "        # Scale and offset specific bands\n",
    "        df_filtered['ST_B10_Celsius'] = df_filtered['ST_B10'] * 0.00341802 + 149 - 273.15\n",
    "        df_filtered = df_filtered[df_filtered['ST_B10_Celsius'] >= 20]  # Drop rows below 20 degrees Celsius\n",
    "        \n",
    "        bands_to_scale = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "        for band in bands_to_scale:\n",
    "            df_filtered[f\"{band}_Scaled\"] = df_filtered[band] * 2.75e-05 - 0.2\n",
    "\n",
    "        additional_scales = {\n",
    "            'ST_ATRAN': 0.0001, 'ST_CDIST': 0.01, 'ST_DRAD': 0.001, \n",
    "            'ST_EMIS': 0.0001, 'ST_EMSD': 0.0001, 'ST_QA': 0.01, \n",
    "            'ST_TRAD': 0.001, 'ST_URAD': 0.001\n",
    "        }\n",
    "\n",
    "        for band, scale in additional_scales.items():\n",
    "            df_filtered[f\"{band}_Scaled\"] = df_filtered[band] * scale\n",
    "\n",
    "        gdf = gpd.GeoDataFrame(df_filtered, geometry=gpd.points_from_xy(df_filtered.Longitude, df_filtered.Latitude))\n",
    "        gdf.set_crs('EPSG:4326', inplace=True)  # Ensure the CRS is set to WGS 84\n",
    "\n",
    "        print(\"Total number of valid pixels: \" + str(len(gdf)))\n",
    "        print(df[['Latitude', 'Longitude']].head())\n",
    "\n",
    "        # Define your point of interest and buffer distance in meters\n",
    "        poi = Point(avg_longitude, avg_latitude)\n",
    "        desired_radius = 90\n",
    "        buffer = poi.buffer(desired_radius / 111320)  # Convert meters to degrees approximately\n",
    "\n",
    "        # Filter points within the buffer\n",
    "        filtered_gdf = gdf[gdf.geometry.within(buffer)]\n",
    "\n",
    "        # Save or process your filtered data\n",
    "        print(f\"\\nNumber of points within {desired_radius}m radius: {len(filtered_gdf)}\")\n",
    "        #print(filtered_gdf['ST_B10_Celsius'].head())\n",
    "\n",
    "    return filtered_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining boundaries and plotting region of interest using GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['osm_id', 'osm_type', 'addr_street', 'building', 'name', 'access_roof',\n",
      "       'building_material', 'addr_housenumber', 'roof_material', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "geojson_path = \"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\SG_geojson\\\\SG.geojson\"\n",
    "\n",
    "geo_data = gpd.read_file(geojson_path)\n",
    "\n",
    "# Display the matching features\n",
    "print(geo_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLYGON ((103.8254384 1.2743995, 103.825484 1.2743955, 103.8254826 1.2743647, 103.8257254 1.274362, 103.8257254 1.2744009, 103.8260325 1.2743915, 103.8260754 1.2744344, 103.8262618 1.274429, 103.8263745 1.2745524, 103.8263785 1.2747656, 103.8262082 1.2747669, 103.8262045 1.274549, 103.8257106 1.2745598, 103.8257079 1.2745108, 103.8254424 1.2745122, 103.8254384 1.2743995))\n"
     ]
    }
   ],
   "source": [
    "matching_features = geo_data[(geo_data['addr_street'].str.contains(\"Bukit Purmei\", na=False)) & \n",
    "                             (geo_data['addr_housenumber'].str.contains(\"112\", na=False))]\n",
    "\n",
    "if not matching_features.empty:\n",
    "    polygon = matching_features.iloc[0]['geometry']\n",
    "    print(polygon)\n",
    "else:\n",
    "    print(\"No matching features found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of valid pixels: 2151197\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 26\n",
      "Launching server at http://localhost:52055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<panel.io.server.Server at 0x26b3e4d1ff0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "import panel as pn\n",
    "from bokeh.palettes import Inferno256 #Viridis256 / Turbo256\n",
    "import logging\n",
    "\n",
    "# Suppress warnings\n",
    "logging.getLogger('bokeh').setLevel(logging.ERROR)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "satellite_image = \"L8_UTC_20201223_031657\"\n",
    "file_path = f\"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\Landsat8\\\\2020_test\\\\2020\\\\{satellite_image}.tif\"\n",
    "\n",
    "# Assuming preprocessing is defined elsewhere and correctly imports the file\n",
    "filtered_gdf = preprocessing(file_path)\n",
    "\n",
    "# Ensure the CRS is set\n",
    "if filtered_gdf.crs is None:\n",
    "    filtered_gdf.set_crs('epsg:4326', inplace=True)  # Assuming the data is in WGS 84\n",
    "\n",
    "# Convert to Web Mercator for better mapping support\n",
    "filtered_gdf = filtered_gdf.to_crs(epsg=3857)\n",
    "\n",
    "# Create a GeoDataFrame for the Polygon (defined earlier)\n",
    "polygon_gdf = gpd.GeoDataFrame({'geometry': [polygon]}, crs='epsg:3857')  # Set the CRS to Web Mercator\n",
    "\n",
    "# Define a function to select a subset of the color palette\n",
    "def select_colors(palette, n):\n",
    "    return [palette[int(i)] for i in np.linspace(0, len(palette)-1, n)]\n",
    "\n",
    "# Create a custom color scale using a continuous palette\n",
    "custom_palette = select_colors(Inferno256, 256)  # More colors for smoother transitions\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = filtered_gdf.hvplot.points('Longitude', 'Latitude', geo=True, c='ST_B10_Celsius', cmap=custom_palette, size=5, tiles='OSM', frame_width=700, frame_height=500, colorbar=True, clim=(20, 40))\n",
    "\n",
    "# Plot the polygon with visible settings\n",
    "polygon_plot = polygon_gdf.hvplot(geo=True, color='red', line_width=3, alpha=0.7)\n",
    "\n",
    "# Overlay the polygon onto the heatmap\n",
    "overlay_map = polygon_plot * heatmap\n",
    "\n",
    "# Set up Panel to display the plot\n",
    "pane = pn.panel(overlay_map)\n",
    "\n",
    "pane.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering 30m x 30m pixels based on region of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using ESPG:3857 allows you to blow up the pixels in metres because the coordinate representation is in metres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of valid pixels: 2151197\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 26\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, box\n",
    "import panel as pn\n",
    "from bokeh.palettes import Inferno256\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Suppress warnings\n",
    "logging.getLogger('bokeh').setLevel(logging.ERROR)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "satellite_image = \"L8_UTC_20201223_031657\"\n",
    "file_path = f\"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\Landsat8\\\\2020_test\\\\2020\\\\{satellite_image}.tif\"\n",
    "\n",
    "# Assuming preprocessing is defined elsewhere and correctly imports the file\n",
    "filtered_gdf = preprocessing(file_path)\n",
    "\n",
    "def plot_spatial_map(filtered_gdf): \n",
    "    # Ensure the CRS is set\n",
    "    if filtered_gdf.crs is None:\n",
    "        filtered_gdf.set_crs('epsg:4326', inplace=True)  # Assuming the data is in WGS 84\n",
    "\n",
    "    filtered_gdf = filtered_gdf.to_crs('epsg:3857')\n",
    "\n",
    "    # print(filtered_gdf['geometry'])\n",
    "\n",
    "    # Create pixels as 30m x 30m boxes around each point\n",
    "    # Assuming each point is at the center of the pixel\n",
    "    half_width = 15  # half the width of the pixel in meters since the ESPG:3857 coordinate system is in metres\n",
    "    filtered_gdf['geometry'] = filtered_gdf['geometry'].apply(lambda x: box(x.x - half_width, x.y - half_width, x.x + half_width, x.y + half_width))\n",
    "\n",
    "    #print(filtered_gdf['geometry'])\n",
    "\n",
    "    # Create a GeoDataFrame for the Polygon (defined earlier)\n",
    "    polygon_gdf = gpd.GeoDataFrame({'geometry': [polygon]}, crs='epsg:4326')  # Assuming the original CRS is EPSG 4326 (WGS84)\n",
    "\n",
    "    # Convert the geometry to EPSG 3857\n",
    "    polygon_gdf_3857 = polygon_gdf.to_crs(epsg=3857)\n",
    "\n",
    "    # print(polygon_gdf_3857['geometry'])\n",
    "\n",
    "    # Choosing pixels that intersect with the polygon\n",
    "    pip = filtered_gdf.intersects(polygon_gdf_3857.loc[0, 'geometry'])\n",
    "\n",
    "    # Creating a new GeoDataFrame that will have only the intersecting pixels\n",
    "    within_polygon_gdf = filtered_gdf.loc[pip].copy()\n",
    "\n",
    "    # Resetting index (optional)\n",
    "    within_polygon_gdf.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Print or use the filtered GeoDataFrame as needed\n",
    "    # print(\"\\nNumber of points within the region of interest: \" + str(len(within_polygon_gdf)))\n",
    "\n",
    "    # # Print the centroids of the intersected pixels\n",
    "    # for index, row in within_polygon_gdf.iterrows():\n",
    "    #     centroid = row['geometry'].centroid\n",
    "    #     print(f\"Longitude: {centroid.x}, Latitude: {centroid.y}\")\n",
    "\n",
    "    # Define a function to select a subset of the color palette\n",
    "    def select_colors(palette, n):\n",
    "        return [palette[int(i)] for i in np.linspace(0, len(palette)-1, n)]\n",
    "\n",
    "    # Create a custom color scale using a continuous palette\n",
    "    custom_palette = select_colors(Inferno256, 256)  # More colors for smoother transitions\n",
    "\n",
    "    # Create the heatmap using the centroid points of intersected pixels\n",
    "    heatmap = within_polygon_gdf.hvplot.points('Longitude', 'Latitude', geo=True, c='ST_B10_Celsius', cmap=custom_palette, size=5, tiles='OSM', frame_width=700, frame_height=500, colorbar=True, clim=(20, 40))\n",
    "\n",
    "    # Plot square polygons with the same color mapping as the points\n",
    "    squares_plot = within_polygon_gdf.hvplot.polygons('geometry', c='ST_B10_Celsius', cmap=custom_palette, alpha=0.5, colorbar=True, clim=(20, 40))\n",
    "\n",
    "    # Plot the polygon with visible settings\n",
    "    polygon_plot = polygon_gdf.hvplot(geo=True, color='red', line_width=3, alpha=0.7)\n",
    "\n",
    "    # Overlay the polygon onto the heatmap\n",
    "    overlay_map = polygon_plot * heatmap * squares_plot\n",
    "\n",
    "    # Set up Panel to display the plot\n",
    "    pane = pn.panel(overlay_map)\n",
    "\n",
    "    # pane.show()\n",
    "    # pane.save(f'C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\MSE-ES-UHI\\\\2_landsat\\\\Heatmaps\\\\{postal_code_112}_{satellite_image}_LST_Filtered.html', embed=True)\n",
    "\n",
    "    return overlay_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting LST over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combining GDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing: L8_UTC_20200106_031650.tif\n",
      "Total number of valid pixels: 1912476\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 27\n",
      "Currently processing: L8_UTC_20200122_031646.tif\n",
      "Total number of valid pixels: 1731121\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 28\n",
      "Currently processing: L8_UTC_20200207_031641.tif\n",
      "Total number of valid pixels: 1216672\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 0\n",
      "Currently processing: L8_UTC_20200223_031638.tif\n",
      "Total number of valid pixels: 1345446\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 26\n",
      "Currently processing: L8_UTC_20200310_031632.tif\n",
      "Total number of valid pixels: 1314431\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 26\n",
      "Currently processing: L8_UTC_20200326_031623.tif\n",
      "Total number of valid pixels: 1395941\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 0\n",
      "Currently processing: L8_UTC_20200411_031615.tif\n",
      "Total number of valid pixels: 924801\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 26\n",
      "Currently processing: L8_UTC_20200427_031608.tif\n",
      "Total number of valid pixels: 0\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 0\n",
      "Currently processing: L8_UTC_20200529_031605.tif\n",
      "Total number of valid pixels: 1377754\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 28\n",
      "Currently processing: L8_UTC_20200614_031616.tif\n",
      "Total number of valid pixels: 37446\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 0\n",
      "Currently processing: L8_UTC_20200630_031624.tif\n",
      "Total number of valid pixels: 1104217\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 26\n",
      "Currently processing: L8_UTC_20200716_031630.tif\n",
      "Total number of valid pixels: 2045133\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 26\n",
      "Currently processing: L8_UTC_20200801_031634.tif\n",
      "Total number of valid pixels: 28641\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 0\n",
      "Currently processing: L8_UTC_20200817_031639.tif\n",
      "Total number of valid pixels: 558821\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 0\n",
      "Currently processing: L8_UTC_20200902_031647.tif\n",
      "Total number of valid pixels: 1445605\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 26\n",
      "Currently processing: L8_UTC_20200918_031653.tif\n",
      "Total number of valid pixels: 1183017\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 27\n",
      "Currently processing: L8_UTC_20201004_031657.tif\n",
      "Total number of valid pixels: 0\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 0\n",
      "Currently processing: L8_UTC_20201020_031658.tif\n",
      "Total number of valid pixels: 0\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 0\n",
      "Currently processing: L8_UTC_20201121_031657.tif\n",
      "Total number of valid pixels: 317897\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 11\n",
      "Currently processing: L8_UTC_20201207_031659.tif\n",
      "Total number of valid pixels: 955530\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 27\n",
      "Currently processing: L8_UTC_20201223_031657.tif\n",
      "Total number of valid pixels: 476280\n",
      "   Latitude   Longitude\n",
      "0  1.470099  103.589751\n",
      "1  1.470099  103.590021\n",
      "2  1.470099  103.590290\n",
      "3  1.470099  103.590560\n",
      "4  1.470100  103.590830\n",
      "\n",
      "Number of points within 90m radius: 26\n",
      "          Longitude  Latitude    SR_B1    SR_B2    SR_B3    SR_B4    SR_B5  \\\n",
      "1280350  103.825495  1.275399   8942.0   9311.0   9974.0   9905.0  15812.0   \n",
      "1280351  103.825765  1.275400   8659.0   9007.0  10040.0   9841.0  16689.0   \n",
      "1280352  103.826035  1.275400   8249.0   8457.0   9337.0   9018.0  13368.0   \n",
      "1280353  103.826304  1.275400   8139.0   8423.0   9341.0   8966.0  15291.0   \n",
      "1282131  103.825226  1.275128   9207.0   9728.0  10998.0  10866.0  20810.0   \n",
      "...             ...       ...      ...      ...      ...      ...      ...   \n",
      "1287478  103.825496  1.274314  10257.0  10797.0  12879.0  12709.0  16967.0   \n",
      "1287479  103.825765  1.274314  10280.0  11603.0  12620.0  12910.0  18384.0   \n",
      "1287480  103.826035  1.274314  10424.0  11165.0  12972.0  13260.0  18003.0   \n",
      "1287481  103.826305  1.274314   8625.0   9187.0  10992.0  10865.0  16466.0   \n",
      "1289261  103.825766  1.274043   9290.0   9911.0  11756.0  11883.0  15425.0   \n",
      "\n",
      "           SR_B6    SR_B7  SR_QA_AEROSOL  ...  ST_ATRAN_Scaled  \\\n",
      "1280350  12905.0  10708.0            160  ...           0.4134   \n",
      "1280351  12779.0  10618.0            224  ...           0.4134   \n",
      "1280352  11567.0  10109.0            224  ...           0.4134   \n",
      "1280353  12573.0  10232.0            224  ...           0.4134   \n",
      "1282131  16586.0  12735.0            160  ...           0.4134   \n",
      "...          ...      ...            ...  ...              ...   \n",
      "1287478  16319.0  13076.0            224  ...           0.3477   \n",
      "1287479  15076.0  11749.0            224  ...           0.3477   \n",
      "1287480  14942.0  12361.0            224  ...           0.3477   \n",
      "1287481  14068.0  11793.0            224  ...           0.3477   \n",
      "1289261  14116.0  12607.0            224  ...           0.3477   \n",
      "\n",
      "         ST_CDIST_Scaled  ST_DRAD_Scaled  ST_EMIS_Scaled  ST_EMSD_Scaled  \\\n",
      "1280350             0.43           2.011          0.9628          0.0000   \n",
      "1280351             0.44           2.011          0.9628          0.0000   \n",
      "1280352             0.46           2.011          0.9578          0.0011   \n",
      "1280353             0.47           2.011          0.9578          0.0011   \n",
      "1282131             0.42           2.011          0.9628          0.0000   \n",
      "...                  ...             ...             ...             ...   \n",
      "1287478             0.00           2.164          0.9636          0.0000   \n",
      "1287479             0.00           2.164          0.9636          0.0000   \n",
      "1287480             0.00           2.164          0.9688          0.0056   \n",
      "1287481             0.00           2.164          0.9688          0.0056   \n",
      "1289261             0.00           2.164          0.9636          0.0000   \n",
      "\n",
      "         ST_QA_Scaled  ST_TRAD_Scaled  ST_URAD_Scaled  \\\n",
      "1280350          4.79        9.482000           4.728   \n",
      "1280351          4.73        9.459001           4.728   \n",
      "1280352          4.66        9.436001           4.728   \n",
      "1280353          4.59        9.417001           4.728   \n",
      "1282131          4.83        9.527000           4.728   \n",
      "...               ...             ...             ...   \n",
      "1287478          7.05        8.502001           5.133   \n",
      "1287479          7.05        8.498000           5.133   \n",
      "1287480          7.06        8.495001           5.133   \n",
      "1287481          7.06        8.495001           5.133   \n",
      "1289261          7.05        8.503000           5.133   \n",
      "\n",
      "                          geometry       time  \n",
      "1280350  POINT (103.82550 1.27540) 2020-01-06  \n",
      "1280351  POINT (103.82577 1.27540) 2020-01-06  \n",
      "1280352  POINT (103.82603 1.27540) 2020-01-06  \n",
      "1280353  POINT (103.82630 1.27540) 2020-01-06  \n",
      "1282131  POINT (103.82523 1.27513) 2020-01-06  \n",
      "...                            ...        ...  \n",
      "1287478  POINT (103.82550 1.27431) 2020-12-23  \n",
      "1287479  POINT (103.82577 1.27431) 2020-12-23  \n",
      "1287480  POINT (103.82604 1.27431) 2020-12-23  \n",
      "1287481  POINT (103.82630 1.27431) 2020-12-23  \n",
      "1289261  POINT (103.82577 1.27404) 2020-12-23  \n",
      "\n",
      "[330 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import shutil\n",
    "\n",
    "year = \"2020\"\n",
    "\n",
    "# Suppress warnings\n",
    "logging.getLogger('bokeh').setLevel(logging.ERROR)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Specify the zip file and temporary directory for extraction\n",
    "zip_file_path = f\"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\Landsat8\\\\{year}.zip\"\n",
    "temp_dir = f\"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\temp_extract\"\n",
    "\n",
    "# Create a temporary directory if it doesn't exist\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# Extract the .tif files from the zip\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(temp_dir)\n",
    "\n",
    "# Initialize an empty list to hold all the GeoDataFrames\n",
    "gdfs = []\n",
    "\n",
    "# Walk through the temporary directory and process each .tif file\n",
    "for filename in os.listdir(f\"{temp_dir}\\\\{year}\"):\n",
    "    if filename.endswith(\".tif\"):\n",
    "        print(\"Currently processing: \" + filename)\n",
    "        file_path = os.path.join(f\"{temp_dir}\\\\{year}\", filename)\n",
    "        \n",
    "        # Extract the time period from the filename\n",
    "        # Assuming filename format is \"L8_UTC_YYYYMMDD_hhmmss.tif\"\n",
    "        time_str = filename.split('_')[2]\n",
    "        time_obj = datetime.strptime(time_str, \"%Y%m%d\")\n",
    "        \n",
    "        # Load and preprocess the GeoDataFrame\n",
    "        gdf = preprocessing(file_path)\n",
    "        gdf['time'] = time_obj  # Append the datetime object as a new column\n",
    "        \n",
    "        # Append the processed GeoDataFrame to the list\n",
    "        gdfs.append(gdf)\n",
    "\n",
    "# Combine all GeoDataFrames into one\n",
    "combined_gdf = pd.concat(gdfs)\n",
    "\n",
    "shutil.rmtree(f\"C:\\\\LocalOneDrive\\\\Documents\\\\Desktop\\\\MTI\\\\UHI-Project\\\\MSE-ES-UHI\\\\Data\\\\temp_extract\")\n",
    "\n",
    "# Use the combined GeoDataFrame as needed\n",
    "print(combined_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spatial plot over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:59368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<panel.io.server.Server at 0x20a497a88e0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import panel as pn\n",
    "\n",
    "# Create an interactive plot with filtering based on the GeoDataFrame\n",
    "def create_interactive_plot(combined_gdf):\n",
    "        # Create a list of unique dates sorted\n",
    "    unique_dates = combined_gdf['time'].dt.strftime('%Y-%m-%d').sort_values().unique()\n",
    "    # print(f\"Unique Dates: {unique_dates}\")\n",
    "\n",
    "    date_index_map = {i + 1: date for i, date in enumerate(unique_dates)}\n",
    "\n",
    "    # Setup an integer slider to select time periods\n",
    "    time_slider = pn.widgets.IntSlider(name='Select Time', start=1, end=len(unique_dates), value=1, step=1)\n",
    "\n",
    "    @pn.depends(time_slider.param.value_throttled)\n",
    "    def dynamic_map(value):\n",
    "        selected_date = date_index_map[value]\n",
    "        selected_datetime = pd.to_datetime(selected_date).date()\n",
    "        \n",
    "        # Filter data for the selected time\n",
    "        filtered_data = combined_gdf[combined_gdf['time'].dt.date == selected_datetime]\n",
    "\n",
    "        # Call plot_spatial_map for the selected time period\n",
    "        return plot_spatial_map(filtered_data)\n",
    "\n",
    "    layout = pn.Column(\n",
    "        \"<br>\\nInteractive Land Surface Temperature Map\",\n",
    "        time_slider,\n",
    "        dynamic_map\n",
    "    )\n",
    "\n",
    "    return layout\n",
    "\n",
    "# Assuming 'combined_gdf' is a GeoDataFrame already loaded and ready to be used.\n",
    "layout = create_interactive_plot(combined_gdf)\n",
    "# layout.servable()\n",
    "pn.serve(layout, show=False, start=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
